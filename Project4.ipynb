{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1><center>Project 4<BR><BR>\n",
    "Recommender Systems</center></H1>\n",
    "    \n",
    "**UPDATE: Resubmitted 11/28! Happy Thanksgiving :) \"\n",
    "**Disclaimer: I ran out of late passes and wanted to at least submit the work I had completed so this version of my project 4 submission lacks much of task 3 at the moment.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Task 1: Algorithmic Bias\n",
    "</H2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>Read <a href=\"https://cacm.acm.org/magazines/2016/10/207759-battling-algorithmic-bias/abstract\">this article</a> about bias in algorithms.</P>\n",
    "\n",
    "<P>Please address (minimum 200 words) the following questions in the space below. As the article describes, \"common wisdom among programmers is to develop a pure algorithm that does not incorporate protected attributes into the model,\" where protected classes may include aspects such as race, gender, age, sexual orientation, and disability status. As a result, the algorithms can be bias. How might algorithms be evaluated for bias? Are there machine learning applications where you would sacrifice accuracy in order to reduce bias? Are there machine learning applications where you would allow bias in order to increase accuracy?</P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Generally, I think that the developers of algorithms should attempt to reduce bias between groups of different protected classes while compromising the performance of the model as little as possible. I prioritize reducing bias because I believe that most often, the groups that will be disproportionately endangered by biased algorithms will be those that are already most at risk in society. I believe that there are several ways to evaluate algorithms for bias: First, we can examine how an algorithm performs on more diverse sets of testing data. In doing so, it is important to protect the privacy of diverse people represented in the data and ensure that their information cannot be traced back to them. Furthermore, we can also adjust our model to explore more complex relationships in data that might require it to go beyond a surface-level understanding of patterns involving complex human characteristics. I would sacrifice accuracy to reduce bias in issues that are more interpersonal in nature but don't have an underlying premise of improving safety: for instance, hiring. Conversely, I would allow for some bias in applications where immediate safety is directly concerned. Nonetheless, I remain concerned that if we allow for only the majority to be protected by our algorithms, we risk harming already vulnerable populations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Task 2: Collaborative Filtering\n",
    "</H2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>In this task, you will use collaborative filtering to predict how a person might rate a business. Ratings are numbers between 1 and 5 corresponding, for example, to how many stars a person gives the business in a review. The data comes from the <a href=\"https://www.yelp.com/dataset/challenge\">Yelp Dataset Challenge</a>.</P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>To begin, read in the <code>training.csv</code> file containing <em>training</em> data. Unlike many other <code>CSV</code> files that we have worked with previously, the data are not in matrix form (rows and columns) here, but rather a list. Each line in the file contains three comma delimited values: the first corresponds to the ID of a person (user), the second correspond to the ID of a business (item), and the third corresponds to the rating (1 through 5) that the person gave the business in a review. The file contains over 80,000 lines, i.e., over 80,000 ratings that people gave to businesses. Write code below to create a user-item matrix, as described in class, from the data in the file. For each line in the file, you can think of the user (person) ID as indicating the row in the user-item matrix, the item (business) ID as indicating the column in the user-item matrix, and the rating as the value to be inserted in the user-item matrix at the specified row and column. Note that your user-item matrix will have many more than 80,000 entries even though the data contain only ~80,000 ratings. Thus, the matrix will be sparse, i.e., most values in the matrix should correspond to zero since each person rates only a small subset of all businesses.</P>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>323</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>830</td>\n",
       "      <td>1831</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>440</td>\n",
       "      <td>167</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>302</td>\n",
       "      <td>1801</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>917</td>\n",
       "      <td>3050</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1  2\n",
       "0    4   323  5\n",
       "1  830  1831  3\n",
       "2  440   167  5\n",
       "3  302  1801  5\n",
       "4  917  3050  4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in training data and create user-item matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_csv('training.csv', header=None)\n",
    "rows = df[0]\n",
    "cols = df[1]\n",
    "ratings = df[2]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['User','Item','ItemRating']\n",
    "sparse = df.pivot(index='User', columns='Item', values='ItemRating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>Ultimately, our goal is to use filled-in (i.e., non-zero) values in the user-item matrix to predict empty (i.e., zero) values in the user-item matrix. In other words, we want to predict how a person might rate a business, based on how a person has rated other businesses or how a business has been rated by other people. Collaborative filtering.</P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<P>Below, write a function named <code>prediction</code> that predicts a value (i.e., rating) for a given location (row index and column index) in the user-item matrix. Your prediction algorithm should proceed as follows:<BR>\n",
    "<UL>\n",
    "<li>Determine all rows in the matrix that contain non-zero values in the specified column. This will give us information on all people that rated the business of interest.</li>\n",
    "<li>Using the <code>sklearn</code> unsupervised <code><a href=\"http://scikit-learn.org/stable/modules/neighbors.html\">NearestNeighbors</a></code> algorithm, for the specified row in the user-item matrix, compute the <em>k</em> nearest neighbors among the rows that contain non-zero values in the specified column. This will give us the <em>k</em> most similar people that rated the business of interest. You should use the <code>cosine</code> metric in the <code>NearestNeighbors</code> algorithm for computing distance between rows in a matrix. If there are fewer than <em>k</em> people who have rated the business, you can use everyone who rated the business rather than the <em>k</em> most similar people (since there aren't <em>k</em> such people.</li>\n",
    "<li>For the <em>k</em> nearest neighbors of the specified row, compute and return the mean value for the specified column. This will give us the average rating of the business from the <em>k</em> most similar people to the person of interest. In other words, we are predicting how someone will rate a business based on the ratings of similar people who have already rated the business.</li>\n",
    "</UL><BR>\n",
    "Your <code>prediction</code> function should have at least four inputs: your user-item matrix, a paramter <em>k</em>, a specified row, and a specified column (as well as any other input parameters that you deem helpful). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The *prediction* function takes in four (or more) parameters corresponding to\n",
    "# the user-item matrix, k, the row (person) index, and the column (business) index.\n",
    "# The function returns the average (mean) rating of a business from the k most\n",
    "# similar people to the specified person.\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def prediction(ui, k, row, col):\n",
    "    item = ui[:][col] #all users at specific column\n",
    "    xrow = ui.iloc[row].fillna(0) #user that we want to find rating for\n",
    "    xrow = xrow.as_matrix()\n",
    "    itemRows = np.argwhere(item.notnull().values).tolist()\n",
    "    \n",
    "    userRows = [] #make flat version of itemRows\n",
    "    for sublist in itemRows:\n",
    "        for i in sublist:\n",
    "            userRows.append(i)\n",
    "            \n",
    "    #make a new dataframe of users that have ratings at specified columns\n",
    "    df2 = ui.iloc[userRows]\n",
    "    df2 = df2.fillna(0)\n",
    "    \n",
    "    #set # of neighbors depending on number of matching users\n",
    "    if df2.shape[0] >= k:\n",
    "        model = NearestNeighbors(metric='cosine', n_neighbors=k).fit(df2)\n",
    "    if df2.shape[0] < k:\n",
    "        model = NearestNeighbors(metric='cosine', n_neighbors=df2.shape[0]).fit(df2)\n",
    "    \n",
    "    #find neighbors for user of interest at column of interest\n",
    "    dist, indices = model.kneighbors(xrow.reshape(1,-1))\n",
    "    \n",
    "    #compute average rating based on ratings of neighbors\n",
    "    avgList = []\n",
    "    for row in indices[0]:\n",
    "        avgList.append(df2.iloc[row][col])\n",
    "    mean = np.mean(avgList)\n",
    "    return(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>Let's evaluate how well we do at predicting people's ratings of businesses. The file <code>testing.csv</code> contains approximately 4,000 ratings that different people have given to different businesses. These <em>testing</em> ratings correspond to ~4,000 entries in the user-item matrix that contain zero values. So we can use the user-item matrix (our <em>training</em> data) to predict ratings in these ~4,000 cases and compare our predictions to the actual rating found in the <em>testing</em> data in order to see how accurate our predicted ratings are.</P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>Write code below that reads in <em>testing</em> data from <code>testing.csv</code>. Each line in the file contains three comma delimited values: the first corresponds to the ID of a person (user), the second correspond to the ID of a business (item), and the third corresponds to the rating (1 through 5) that the person gave the business in a review. For each line, use the <code>prediction</code> function that you wrote above to predict the rating that the specified user might give the specified business. Keep track of this predicted rating as well as the actual rating from the <em>testing</em> data. After processing all lines in the <em>testing</em> file, you should have ~4,000 predicted ratings and the same number of actual ratings. To compare how far our predictions are from the actual ratings, we'll compute the root mean-squared error (RMSE) between the two, e.g., by computing the square root of the <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html\">mean-squared error</a> (MSE). As a point of reference, the instructor found a RMSE a bit under 1.0 depending on the value of <em>k</em> used, i.e., the predicted ratings were a bit less than 1 \"star\" from the actual ratings on average. Try computing the RMSE on the <em>testing</em> data for each of the following eleven values for the parameter <em>k</em>: 1, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50.</P>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4.1, 3.5, 3.9, ..., 4.1, 3.9, 3.9])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in testing data and for each line in the file,\n",
    "# calculate the predicted rating of the specified person and business.\n",
    "# Compare the predicted ratings with the actual ratings in the testing data\n",
    "# by computing the root mean-squared error (RMSE).\n",
    "# Compute the RMSE for 11 different values of parameter k: 1,5,10,15,20,25,30,35,40,45,50\n",
    "\n",
    "df = pd.read_csv('testing.csv', header=None)\n",
    "df.columns = ['User','Item','ItemRating']\n",
    "df.columns = ['User','Item','ItemRating']\n",
    "\n",
    "results = df[['ItemRating']]\n",
    "\n",
    "df = df.drop(columns=['ItemRating'])\n",
    "df.head()\n",
    "ratings = np.zeros(df.shape[0])\n",
    "for i in range(df.shape[0]):\n",
    "    ratings[i] = prediction(sparse,10,df.iloc[i][0],df.iloc[i][1])\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 3, 4, ..., 5, 4, 4])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trueList = [] #make flat version of results.values\n",
    "for sublist in results.values:\n",
    "    for i in sublist:\n",
    "        trueList.append(i)\n",
    "trueArr = np.asarray(trueList)\n",
    "trueArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8743359918901499"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "y_true = trueArr\n",
    "y_pred = ratings\n",
    "mean_squared_error(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "ks = [1, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
    "ratingsK = np.zeros((len(ks),df.shape[0]))\n",
    "rmsArr = np.zeros(len(ks))\n",
    "for k in range(len(ks)):\n",
    "    for i in range(df.shape[0]):\n",
    "        ratingsK[k][i] = prediction(sparse,ks[k],df.iloc[i][0],df.iloc[i][1])\n",
    "    rmsArr[k] = mean_squared_error(y_true, ratingsK[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.44915062, 0.94519466, 0.87433599, 0.86201803, 0.85863899,\n",
       "       0.85894258, 0.8591207 , 0.8597084 , 0.8596854 , 0.85918819,\n",
       "       0.86063692])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmsArr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<P><font color=\"maroon\"><u>For which of the eleven values of <em>k</em> do you observe the smallest RMSE? What is the RMSE at this optimal value of <em>k</em>?<u></font></P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The lowest RMSE was 0.85863899 at k = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<P>Above, you predicted how a user might rate a business by seeing how similar users rated the same business (and taking the average value of these similar users' ratings of the business). As an alternative method for predicting the rating a user might give to a business, we could look at similar <em>businesses</em> rather than similar <em>users</em>. In this alternative approach, we will take our user and find similar <em>businesses</em> that they have rated. Our predicted rating will be the mean value of the user's ratings of <em>k</em> similar businesses. Below, write code to compute the RMSE between predicted ratings and actual ratings using eleven different values for the parameter <em>k</em>: 1, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50. Predicted ratings should be determined by calculating, among businesses rated by a specified user, the average rating that the user gave to the <em>k</em> most similar businesses. <em>Hint: You needn't change your <code>prediction</code> function above. Changing a single line of code elsewhere may be sufficient.</em></P>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>User</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>908</th>\n",
       "      <th>909</th>\n",
       "      <th>910</th>\n",
       "      <th>911</th>\n",
       "      <th>912</th>\n",
       "      <th>913</th>\n",
       "      <th>914</th>\n",
       "      <th>915</th>\n",
       "      <th>916</th>\n",
       "      <th>917</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Item</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 918 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "User  0    1    2    3    4    5    6    7    8    9   ...   908  909  910  \\\n",
       "Item                                                   ...                   \n",
       "0     4.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
       "1     4.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  5.0   \n",
       "2     2.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
       "3     4.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  3.0   \n",
       "4     2.0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN ...   NaN  NaN  NaN   \n",
       "\n",
       "User  911  912  913  914  915  916  917  \n",
       "Item                                     \n",
       "0     NaN  NaN  NaN  NaN  5.0  NaN  NaN  \n",
       "1     NaN  NaN  NaN  NaN  3.0  NaN  NaN  \n",
       "2     NaN  NaN  NaN  NaN  3.0  NaN  NaN  \n",
       "3     NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "4     NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "\n",
       "[5 rows x 918 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in testing data and for each line in the file,\n",
    "# calculate the predicted rating of the specified person and business.\n",
    "# Compare the predicted ratings with the actual ratings in the testing data\n",
    "# by computing the root mean-squared error (RMSE).\n",
    "# Compute the RMSE for 11 different values of parameter k: 1,5,10,15,20,25,30,35,40,45,50\n",
    "\n",
    "df3 = pd.read_csv('training.csv', header=None)\n",
    "df3.columns = ['User','Item','ItemRating']\n",
    "sparse3 = df3.pivot(index='Item', columns='User', values='ItemRating')\n",
    "sparse3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3.9, 3.5, 3.7, ..., 2.9, 3.5, 3.5])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3T = pd.read_csv('testing.csv', header=None)\n",
    "df3T.columns = ['User','Item','ItemRating']\n",
    "df3T.columns = ['User','Item','ItemRating']\n",
    "\n",
    "results3 = df3T[['ItemRating']]\n",
    "\n",
    "df3T = df3T.drop(columns=['ItemRating'])\n",
    "df3T.head()\n",
    "\n",
    "ratings = np.zeros(df3T.shape[0])\n",
    "for i in range(df3T.shape[0]):\n",
    "    ratings[i] = prediction(sparse3,10,df3T.iloc[i][1],df3T.iloc[i][0])\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 3, 4, ..., 5, 4, 4])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trueList = [] #make flat version of results.values\n",
    "for sublist in results3.values:\n",
    "    for i in sublist:\n",
    "        trueList.append(i)\n",
    "trueArr = np.asarray(trueList)\n",
    "trueArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "ksT = [1, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50]\n",
    "ratingsKT = np.zeros((len(ksT),df3T.shape[0]))\n",
    "rmsArrT = np.zeros(len(ksT))\n",
    "for k in range(len(ksT)):\n",
    "    for i in range(df3T.shape[0]):\n",
    "        ratingsKT[k][i] = prediction(sparse3,ksT[k],df3T.iloc[i][1],df3T.iloc[i][0])\n",
    "    rmsArrT[k] = mean_squared_error(trueArr, ratingsKT[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.59479049, 0.95605889, 0.88927366, 0.86871762, 0.85748533,\n",
       "       0.85316512, 0.84970183, 0.84752743, 0.84711902, 0.84662163,\n",
       "       0.84849161])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmsArrT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<P><font color=\"maroon\"><u>For which of the eleven values of <em>k</em> do you observe the smallest RMSE? What is the RMSE at this optimal value of <em>k</em>?<u></font></P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Smallest RMSE = 0.84662163 at k = 45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<P><font color=\"maroon\"><u>For their optimal values of parameter <em>k</em>, which approach led to more accurate predictions: (1) among users that have rated a business, finding the average rating that the <em>k</em> most similar users gave the business or (2) among businesses rated by a user, finding the average rating that the user gave to the <em>k</em> most similar businesses?<u></font></P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "(2) led to more accurate predictions since we achieved a lower RMSE than from (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<H2>Task 3: Content Based Recommendations\n",
    "</H2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<P>In Task 2 above, you predicted ratings based only on other ratings, e.g., based on the ratings different users gave the same business or based on ratings the same user gave different businesses. But what if you used other data about users or businesses to make predictions? For example, you might consider a business's type, market, location, or revenue when making predictions or a user's demographic info, spending habits, or preference for different business types when making predictions. Content based recommendations.</P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>Here, we will consider the text of users' reviews of businesses to predict whether a user is likely to write a review of some other business or not. We will again use data from the <a href=\"https://www.yelp.com/dataset/challenge\">Yelp Dataset Challenge</a> but this time, rather than using ratings (1 through 5), we will use reviews (e.g., \"Food was great, service was fast. I would eat here again.\").\n",
    "</P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>To begin, read in the file <code>businesses.txt</code>, which contains the reviews of ~3,000 businesses in the Las Vegas area. Each line of the file contains the ID of a business followed by a tab followed by all the reviews for the business concatenated together. Thus, if 30 people reviewed a particular business, the line in the file corresponding to the business would have the business's ID followed by all 30 reviews aggregated together. You should store the business IDs in one list and the corresponding business reviews in a second list that will serve as a corpus of text documents.</P>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in file containing business IDs and business reviews.\n",
    "# Create two lists, one to store business IDs and one to store business reviews.\n",
    "\n",
    "data = []\n",
    "filereader = open('businesses.txt','r')\n",
    "file = filereader.readline()\n",
    "while(file):\n",
    "    file = file.replace('\\n','').replace('\\\\n','').replace('\\\\','').split('\\t')\n",
    "    data.append(file)\n",
    "    file = filereader.readline()\n",
    "filereader.close()\n",
    "ids = [file[0] for file in data]\n",
    "revs = [file[1] for file in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>Featurize the corpus of business reviews as bag-of-words and TF-IDF weighting (remember Exercise 3?) using <code>sklearn</code>'s <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\"><code>TfidVectorizer</code></a>. Use both bi-grams and uni-grams for features rather than just uni-grams. With uni-grams, we might have ~80,000 features, but with bi-grams as well, we'll have ~2 million features.\n",
    "<em>HINT: by default, the <code>transform</code> and <code>fit_transform</code> functions of a <code>TfidfVectorizer</code> will return sparse matrices, which are efficient to work with. In some cases, invoking the <code>toarray</code> function is desirable to convert the matrices to traditional <code>numpy</code> arrays, but in this case, you should not use the <code>toarray</code> function as working with the default sparse matrices is important for efficiency given the large size of the dataset that you are working with.</em></P>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features from text of reviews using bag-of-words with TF-IDF weighting.\n",
    "# As features, use bi-grams rather than uni-grams.\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "v = TfidfVectorizer(ngram_range=(1, 2),smooth_idf=True)\n",
    "X_train = v.fit_transform(revs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>The <em>testing</em> data relates to 400 users and comes in two files. The file <code>test_reviews.txt</code> contains 400 lines, one for each user, where each line contains a user's ID followed by a tab followed by the text of all the user's reviews concatenated together. The file <code>test_business.txt</code> also contains 400 lines, one for each user, where each line contains a user's ID followed by a tab followed by a tab delimited list of business IDs for the businesses that the user has reviewed. Below, write code to read in the data from the two files, <code>test_reviews.txt</code> and <code>test_business.txt</code>. For the text of users' reviews, you should featurize the text using the <code>TfidVectorizer</code> that you instantiated and trained above, so that you will have matrix (array) with 400 rows (one per user) and over 2 million columns (corresponding to the bi-gram features). <em>HINT: once again, it is recommended that after invoking the <code>transform</code> function on a <code>TfidfVectorizer</code> that you use the returned sparse matrix for efficiency reasons and not convert the matrix to a <code>numpy</code> array using the <code>toarray<code> function.</em></P>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in test data from two files containing (1) text of each user's reviews and \n",
    "# (2) the business IDs for the businesses that each user has reviewed.\n",
    "# Featurize the text of users' reviews using the trained TfidVectorizer created earlier.\n",
    "\n",
    "datat = [[],[]]\n",
    "filereader = open('test_businesses.txt','r')\n",
    "file = filereader.readline()\n",
    "while(file):\n",
    "    file = file.replace('\\n','').replace('\\\\n','').replace('\\\\','').split('\\t')\n",
    "    datat[0].append(file[0])\n",
    "    datat[1].append(file[1:])\n",
    "    file = filereader.readline()\n",
    "filereader.close()\n",
    "usert = datat[0]\n",
    "bizt = datat[1]\n",
    "\n",
    "data = []\n",
    "filereader = open('test_reviews.txt','r')\n",
    "file = filereader.readline()\n",
    "while(file):\n",
    "    file = file.replace('\\n','').replace('\\\\n','').replace('\\\\','').split('\\t')\n",
    "    data.append(file)\n",
    "    file = filereader.readline()\n",
    "filereader.close()\n",
    "idst = [file[0] for file in data]\n",
    "revst = [file[1] for file in data]\n",
    "\n",
    "X_test = v.transform(revst)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>It is not easy to predict what new businesses a user will review in the future based only on the text of a user's previous reviews (we are not even considering which businesses the user has visited previously or the locations of businesses!). But we'll give it a try. Expect the accuracy of our predictions to be low.</P>\n",
    "\n",
    "<P>In order to predict the businesses that a user is likely to review, we'll compare the text of all reviews (from other users) for a business with the text of all reviews from a user. If the text of a business's reviews is similar (i.e., has similar bi-gram features) to the text of a user's reviews, we will predict that the user will review the business. Using <code>sklearn</code>'s <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html\"><code>cosine_similarity</code></a> function, write code below to compute the similarity of each user's featurized text reviews with each business's featurized text reviews.</P>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using sklearn's cosine_similarity function, compute the similarity of \n",
    "# each user's featurized text reviews with each business's featurized text reviews.\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "sim = cosine_similarity(X_test,X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.58946464, 0.69378544, 0.48963578, ..., 0.07053503, 0.11905741,\n",
       "        0.14119936],\n",
       "       [0.59327065, 0.70905669, 0.4831291 , ..., 0.0558425 , 0.11536009,\n",
       "        0.13263431],\n",
       "       [0.06284071, 0.07718672, 0.04912917, ..., 0.00907744, 0.020372  ,\n",
       "        0.01791243],\n",
       "       ...,\n",
       "       [0.61330119, 0.69960985, 0.51542029, ..., 0.06496702, 0.11151165,\n",
       "        0.14181744],\n",
       "       [0.16734157, 0.18593662, 0.1260974 , ..., 0.02379909, 0.03792786,\n",
       "        0.05322412],\n",
       "       [0.13095775, 0.15526743, 0.11000622, ..., 0.01270252, 0.02107398,\n",
       "        0.02455734]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>For a given similarity threshold, say 0.5, we'll predict that a user will review a business if the similarity betweeen the featurized text of their reviews and the featurized text of the business's reviews is above the threshold. In this way, for a given similarity threshold, we can predict whether each user will review each business.</P>\n",
    "\n",
    "<P>We also want to evalute our predictions. Do the businesses that we predict a user will review correspond to the actual businesses that a user has reviewed (from the file <code>test_business.txt</code>)? Write a function <code>evaluate</code> below that predicts the businesses each user will review and then evaluates these predictions. The predictions should be evaluated by computing whether the predictions correspond to true positives, false positives, true negatives, or false negatives. A true positive prediction occurs when we predict a user will review a business and the user has actually reviewed that business. A false positive prediction occurs when we predict a user will review a business but the user has not actually reviewed that business. A true negative prediction occurs when we do not predict a user will review a business and the user has not actually reviewed the business. A false negative prediction occurs when we do not predict a user will review a business but the user has actually reviewed the business. The <code>evaluate</code> function should compute, for a given similarity threshold, the true positives, false positives, true negatives, and false negatives for all users possibly reviewing all businesses. The function should return the recall and the precision of all possible predictions for a given similarity threshold. As input the function should take a similarity threshold as well as any other input parameters you deem appropriate. You should then execute your <code>evaluate</code> function using eleven different similarity threshold values: 0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, and determine the recall and precision for each.</P>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design a function *evaluate* that takes a similarity threshold as input\n",
    "# along with any other appropriate input parameters. The function should\n",
    "# predict for each user the set of businesses that the user is likely to\n",
    "# review by determing if the user's featurized text reviews are similar\n",
    "# (above the threshold) to a business's featurized text reviews.\n",
    "# The function should return the recall and precision of all predictions\n",
    "# by evaluating whether the predictions correspond to actual businesses \n",
    "# reviewed by users.\n",
    "# As a final step, the function should be executing using 11 different\n",
    "# similarity thresholds: 0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0,\n",
    "# so that 11 recall and precision values are determined.\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "thresh = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "def evaluate(t,sim,revs):\n",
    "    pred = np.greater_equal(sim,t)\n",
    "    TP = np.sum(np.logical_and(pred==True,revs==True))\n",
    "    FP = np.sum(np.logical_and(pred==True,revs==False))\n",
    "    TN = np.sum(np.logical_and(pred==False,revs==False))\n",
    "    FN = np.sum(np.logical_and(pred==False,revs==True))\n",
    "    precision = (TP+1)/((TP+FP)+1)\n",
    "    recall = TP/(TP+FN)            \n",
    "    return precision,recall\n",
    "treviews = np.array([np.isin(ids,bizt[i]) for i in range(len(bizt))])          \n",
    "evaluate(0.5,sim,treviews)\n",
    "p = []\n",
    "r = []\n",
    "for t in thresh:\n",
    "    scores = evaluate(t,sim,treviews)\n",
    "    p.append(scores[0])\n",
    "    r.append(scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P><font color=\"maroon\"><u>Below, write code to plot the recall and precision using the eleven different similarity threhsolds. Your plot might look something like this:<BR>\n",
    "<center><img src=\"recall_precision.png\" width=300></img></center><u></font></P>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot recall and precision of predictions using eleven different similarity thresholds.\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(r,p)\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P><font color=\"maroon\"><u>Below, write code to calculate and plot the F1 score on the y-axis and the eleven different similarity threhsolds on the x-axis. Your plot might look something like this:<BR>\n",
    "<center><img src=\"f1.png\" width=300></img></center><u></font></P>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute and plot F1 score of predictions using eleven different similarity thresholds.\n",
    "\n",
    "f1 = np.zeros(len(p))\n",
    "for i in range(len(p)):\n",
    "    f1[i] = 2*(p[i]*r[i])/(p[i]+r[i])\n",
    "plt.plot(thresh,f1)\n",
    "plt.xlabel(\"Similarity threshold\")\n",
    "plt.ylabel(\"F1 score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Submitting your work\n",
    "</H2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P><font color=\"maroon\"><u>Please indicate your name and the names of any partner that worked with you on this project:</u></font></P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name(s): Shreya Parjan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P><font color=\"maroon\"><u>Please indicate anyone else that you collaborated with in the process of doing the project:</u></font></P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collaborators: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P><font color=\"maroon\"><u>If you or your partner is using a late coupon, please indicate who is using the coupon and how many coupons:</u></font></P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Late coupons: Shreya Parjan, all\n",
    "**Disclaimer: I ran out of late passes and wanted to at least submit the work I had completed so this version of my project 4 submission lacks much of task 3 at the moment.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P><font color=\"maroon\"><u>When working on this project, approximately how many hours did you spend on each of (1) Task 1, (2) Task 2, (3) Task 3, and (4) Total?</u></font></P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hours on Task 1: 0.5\n",
    "Hours on Task 2: 8\n",
    "Hours on Task 3: 0.5\n",
    "Total hours: 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P><font color=\"maroon\"><u>When working on this project, did you abide by the <a href=\"https://www.wellesley.edu/studentlife/aboutus/honor\">Honor Code</a> and is all of the work that you are submitting your own and/or your partner's?</u></font></P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abide by Honor Code: yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P><font color=\"maroon\"><u>To submit this project, please upload your <code>Project4.ipynb</code> file to the <code>Project4</code> folder that the instructor created and shared with you in your Google drive.</u></font></P>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
